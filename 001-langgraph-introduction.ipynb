{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generative AI vs Agentic AI\n\n![Image](https://lh3.googleusercontent.com/pw/AP1GczPwEA6Kyb5MqyDiXZ0EfY-ujegGH3cZmHjlERbdUMvgAhcMS9lVngMEdylSH6aZsMJvtCygF7kaStUlhsJ4POhmc9TpAzfrzn5Jnuzwv1hdnBeuXSY=w2400)\n\n### **What is Generative AI (GenAI)?**\n*   **Definition:** Generative AI refers to a class of AI models capable of **creating new content** such as text, images, audio, code, or video that resembles human-created data. In simple terms, it's a branch of AI where models create new data in various modalities (text, image, video), and this generated data feels as if a human being created it.\n*   **Impact and Timeline:** GenAI is a new, powerful, transformative technology that emerged only three years ago and has since revolutionized the world. It elicits both excitement due to its capabilities and fear of job displacement.\n*   **Journey and Examples of Successful Products (over the last 3 years):**\n    *   **LLM-based applications/Chatbots:** The journey of GenAI began about three years ago with products like **ChatGPT**, which has significantly impacted how people interact with search and information. Other examples include Google's **Gemini**, **Claude**, and **Grok**. These chatbots can generate human-like text and are highly intelligent.\n    *   **Image Generation Models:** Diffusion-based models like **DALL-E** and **Midjourney** are very popular. Users provide a text description, and the models quickly generate corresponding images.\n    *   **Code Generation LLMs:** Large Language Models fine-tuned to write software code, such as **Code Llama**.\n    *   **Text-to-Speech (TTS) Models:** Models that convert text descriptions into speech that sounds like a real human voice, with **ElevenLabs** as a prominent example.\n    *   **Video Generation Models:** Models like **Sora** that take a textual description and produce a short video clip.\n*   These products demonstrate GenAI's ability to mimic human creativity, leading to its rapid adoption across industries. GenAI is constantly evolving and improving, as seen in the reduction of spelling mistakes in generated images over time.\n\n### **Generative AI vs. Traditional AI Systems**\nTo understand the true power of GenAI, it's helpful to compare it with Traditional AI systems.\n*   **Traditional AI Systems:**\n    *   Focus on **finding patterns** or identifying the **relationship between input and output** in given data.\n    *   The goal is to predict an output for new inputs based on learned relationships.\n    *   **Examples:**\n        *   **Classification problems:** Determining if an email is spam or not, or if a patient's X-ray indicates cancer. Models learn from data (e.g., chest image and cancer status) to predict for new images.\n        *   **Regression problems:** Predicting a continuous output, such as today's temperature or a company's stock price, based on past data. Models try to find mathematical relationships between input and output.\n*   **Generative AI Systems:**\n    *   Fundamentally different because they don't seek input-output relationships.\n    *   Instead, they try to **understand the entire data's distribution**, its inherent nature, or \"disposition\".\n    *   **Example:** If given many cat images, a GenAI model learns how real-life cats look and their distribution. Once it understands this, it can **generate a new sample** (a new image of a cat) from that distribution.\n    *   **Key attribute:** GenAI produces **highly refined and perfect output** that feels as if a human being created it.\n\n### **Common Applications of Generative AI**\nGenAI is being applied in many domains due to its ability to create human-like content.\n*   **Creative and Business Writing:** Used for drafting blogs from outlines, generating formal business emails, summarizing emails, and drafting replies in tools like Gmail.\n*   **Software Development:** Assists with auto-completion of code and debugging errors by explaining them.\n*   **Customer Support:** Companies use GenAI-powered chatbots to handle customer queries at scale. If a chatbot cannot resolve an issue, it forwards it to a human executive.\n*   **Education:** Transforms online learning by helping clear doubts (e.g., explaining parts of a YouTube video), building personalized curricula, and simplifying complex topics.\n*   **Designing (Images & Video):** Graphic designers can generate thumbnails or infographics with text descriptions using AI tools. Advertising firms can create short video clips for advertisements using tools like Sora or Runway.\n\n### **Practical Scenario: HR Recruiter Task**\nThe video presents a task for an HR recruiter to hire a Backend Engineer. The steps involved are:\n1.  **Drafting a Job Description (JD):** Creating a document detailing requirements, skill set, eligibility, salary, and expectations.\n2.  **Posting the JD:** Publishing the JD on job platforms like LinkedIn or Naukri.com.\n3.  **Shortlisting Applications:** Screening resumes to select a small number of candidates (e.g., 25 out of 1000) for interviews.\n4.  **Interviewing Candidates:** Conducting interviews to find the best fit.\n5.  **Rolling out Offer Letter:** Extending an offer to the selected candidate.\n6.  **Onboarding:** Managing the new employee's onboarding process.\n\n### **Solving the Problem with Generative AI (Simple LLM-Based Chatbot)**\nThe recruiter is provided with a simple LLM-based chatbot that can chat and provide help.\n*   **JD Drafting:** The chatbot can **instantly generate a JD** based on the recruiter's specifications (e.g., \"Backend Engineer with 2-4 years of experience\").\n*   **Job Posting Advice:** The chatbot can suggest platforms like LinkedIn or Naukri based on its training knowledge. (Recruiter still posts manually).\n*   **Shortlisting Advice:** Provides generic advice based on the JD (e.g., look for Python, cloud, startup, or project leadership experience). (Recruiter still manually reviews resumes).\n*   **Interview Scheduling:** Drafts an email to invite shortlisted candidates for an interview.\n*   **Interview Questions:** Generates a question bank based on the JD and its training data, covering topics like backend development experience, frameworks, and problem-solving.\n*   **Offer Letter Drafting:** Instantly generates an offer letter for the selected candidate.\n*   **Overall:** The GenAI chatbot assists at every step, making tasks easier and improving output quality compared to the pre-GenAI era where all tasks were manual.\n\n### **Problems with the Simple Generative AI Solution**\nDespite its usefulness, this GenAI solution has limitations:\n1.  **Reactive:** The chatbot only provides solutions when prompted by the human; it cannot proactively understand the flow or next steps.\n2.  **Lack of Memory/Context Awareness:** It doesn't remember past interactions. The user has to re-provide context for subsequent queries.\n3.  **Generic Advice:** The advice or content generated is generic and not tailored to the specific company's DNA or internal policies.\n4.  **Inability to Take Actions:** The chatbot can draft content (JD, email) but **cannot perform actions independently** (e.g., cannot post the JD on a job portal or send an email itself).\n5.  **Inability to Adapt:** The chatbot cannot adapt to unexpected problems or deviations from the planned flow on its own. It needs human intervention to identify and address issues.\n\n### **Improvement 1: RAG-Based Chatbot (Retrieval Augmented Generation)**\nTo address the \"generic advice\" problem, the GenAI chatbot is improved by connecting it to the company's knowledge base.\n*   **Method:** The chatbot is provided with company-specific documents:\n    *   Past JD templates (including high-performing ones and variations like remote/in-office, junior/senior).\n    *   Hiring strategy/playbook (best platforms, best practices, internal salary bands, shortlisting pointers, past interview question banks).\n    *   Onboarding documents (offer letter templates, welcome email templates, employee policies).\n*   **Result:** The chatbot becomes a **RAG-based chatbot**, providing **tailor-made, company-specific advice** by referencing these documents.\n*   **RAG-based Chatbot in HR Scenario:**\n    *   **JD Drafting:** Automatically incorporates company-specific details like tech stack (Python, Django) and appropriate salary based on experience level without explicit input.\n    *   **Job Posting Advice:** Recommends platforms that yielded the best results for the company in the past.\n    *   **Shortlisting:** Provides customized pointers based on past successful shortlistings (e.g., Python, Django, AWS, prior startup experience) and can identify best-matching candidates if resumes are uploaded.\n    *   **Interview Scheduling:** Generates email templates for interview scheduling based on company's preferred format.\n    *   **Interview Questions:** Accesses the company's past interview question bank for similar profiles.\n    *   **Offer Letter:** Generates an offer letter in the company's specific style and format.\n*   **Overall:** This RAG-based chatbot is **much more useful** by providing specific, customized advice.\n\n### **Remaining Problems After RAG Improvement**\nEven with RAG, some fundamental problems persist:\n1.  **Still Reactive:** The chatbot still only responds to human queries; it doesn't initiate actions.\n2.  **Still No Context Awareness/Memory:** It still forgets previous conversations and requires re-contextualization.\n3.  **Still Cannot Take Actions Independently:** It can draft content but cannot execute tasks like posting JDs or sending emails.\n4.  **Still Cannot Adapt:** It cannot autonomously identify and resolve problems that arise in the process.\n\n### **Improvement 2: Tool-Augmented Chatbot**\nTo enable the chatbot to take actions, it is integrated with various external tools.\n*   **Method:** The chatbot is connected with **APIs** of different services:\n    *   **LinkedIn API:** To communicate with LinkedIn (e.g., post jobs).\n    *   **Resume Parser Tool:** To intake PDF resumes and understand their content.\n    *   **Calendar Tool:** To check availability and schedule events.\n    *   **Mail API:** To send and receive emails.\n    *   **Human Resource Management (HRM) Software:** For various HR-related tasks.\n*   **Result:** This is called a **Tool-Augmented Chatbot**, as it has additional powers to access tools beyond just providing textual replies.\n*   **Tool-Augmented Chatbot in HR Scenario:**\n    *   **JD Drafting:** Still uses RAG to draft company-specific JDs.\n    *   **Automated Job Posting:** The chatbot can **automatically post the JD on LinkedIn and Naukri** by hitting their APIs, saving the recruiter time.\n    *   **Monitoring Applications (Partial):** The chatbot can **check how many applications are received** via LinkedIn access.\n    *   **Problem Identification & Strategy Adjustment (Reactive):** If few applications are received, the chatbot can suggest solutions (e.g., broaden JD, boost post on LinkedIn) based on the company's hiring playbook. It can then **revise the JD and boost the post on LinkedIn automatically** upon human approval.\n    *   **Automated Shortlisting:** The chatbot uses the **resume parser tool** to download, study, and match resumes against the JD, identifying strong candidates. It can then **email the profiles** to the recruiter.\n    *   **Automated Interview Scheduling:** Checks recruiter's availability via **Calendar API** and **sends invitation emails** to candidates and the recruiter.\n    *   **Interview Questions:** Still provides a list of questions from the company database.\n    *   **Automated Offer Letter:** Drafts the offer letter and **sends it directly** to the candidate via Mail API, also tracking replies.\n    *   **Automated Onboarding:** Upon offer acceptance, the chatbot can **trigger the entire onboarding process** via the **HRM software**, including generating employment contracts, creating official email IDs, assigning laptops, and planning KT sessions. It can also **send welcome emails** and **setup intro meetings**.\n*   **Overall:** The tool-augmented chatbot significantly simplifies the recruiter's job by automating many actions, reducing manual effort.\n\n### **Remaining Problems After Tool-Augmentation**\nDespite significant progress, the following problems still exist:\n1.  **Still Reactive:** The human still initiates actions and tells the chatbot what to do next.\n2.  **Still No Context Awareness/Memory:** The chatbot still lacks memory of past steps or overall context, requiring repeated guidance.\n3.  **Still Cannot Adapt:** The chatbot cannot autonomously strategize or adapt when a flow doesn't execute correctly. It identifies problems only when prompted or after a deviation and then waits for human instruction.\n\n### **Final Improvement: AI Agent (Agentic AI Chatbot)**\nThe ultimate goal is to create a chatbot that is **proactive, context-aware, and adaptable**. This is what an **AI Agent** (or Agentic AI chatbot) embodies.\n*   **Characteristics of an AI Agent:**\n    *   **Proactive:** Takes initiative independently.\n    *   **Context-Aware/Memory:** Remembers past actions and understands the overall context and next steps.\n    *   **Adaptable:** Can choose alternate paths when a plan doesn't execute correctly, identifying and solving problems on its own.\n*   **How it Works:** The human provides an **end goal**, and the AI Agent:\n    *   **Understands the goal** deeply.\n    *   **Plans the entire execution path** autonomously.\n    *   **Executes each step** of the plan itself.\n    *   **Monitors progress** continuously.\n    *   **Identifies problems** proactively.\n    *   **Suggests or takes corrective actions** without explicit human prompting.\n    *   Keeps humans in the loop mainly for **approvals**.\n*   **Agentic AI in HR Scenario (Magical Implementation):**\n    *   **Goal Understanding & Self-Planning:** The recruiter simply states, \"I want to hire a Backend Engineer.\" The agent **understands the entire goal** (remote, 2-4 years experience) and **autonomously plans all necessary steps** (JD, posting, monitoring, strategy adjustment, screening, interviews, offer, onboarding).\n    *   **Automated JD & Posting:** The agent first drafts the JD (using company documents) and then **immediately posts it on LinkedIn and Naukri** using APIs, informing the recruiter about each step.\n    *   **Proactive Monitoring & Adaptation:** The agent continuously monitors applications. If it notices low applications (e.g., only two), it **proactively identifies the problem**, **suggests solutions** (broaden JD, promote post), and upon approval, **revises the JD and runs ads automatically**.\n    *   **Proactive Screening & Scheduling:** When enough applications arrive, the agent **notifies the recruiter**, states that it has **already screened all applications** (using resume parser), identified strong candidates, and asks for approval to schedule interviews. It then **checks calendar availability** and **schedules interviews automatically**, sending invites to both parties.\n    *   **Automated Interview Prep:** On the interview day, it **sends reminders** and **emails a document with interview questions** drawn from past hiring data.\n    *   **Automated Offer & Onboarding:** After the recruiter selects a candidate, the agent **drafts and sends the offer letter automatically**, tracking its status. Once accepted, it **triggers the entire onboarding process** (welcome email, IT access request, laptop provisioning) via the HRM software, and even **sets up an intro meeting** between the recruiter and new hire.\n*   **Overall:** The agentic AI system provides immense **autonomy**, allowing the recruiter to primarily **monitor and provide approvals**, while the system handles all the heavy lifting.\n\n### **Conclusion: Generative AI vs. Agentic AI**\nThe discussion concludes by highlighting the fundamental differences derived from the evolution demonstrated.\n*   **Generative AI:**\n    *   **Focus:** Primarily on **content creation** (text, images, video).\n    *   **Nature:** Is **reactive**; humans guide it at every step.\n    *   **Role in Agentic AI:** It is a **building block** or a **subset** of Agentic AI. Agentic AI uses Generative AI elements (like LLMs for planning and reasoning) to achieve its goals.\n    *   **Analogy:** Described as a **capability**.\n*   **Agentic AI:**\n    *   **Focus:** On **achieving a given goal** through planning and step-by-step execution.\n    *   **Nature:** Is **proactive** and **autonomous**. It understands the goal, plans, executes, and keeps humans in the loop mainly for approvals.\n    *   **Components:** A broader term that incorporates many capabilities, including Generative AI, tools, planning, reasoning, and memory.\n    *   **Analogy:** Described as a **behavior**.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# 1. Introduction to LangGraph\nLangGraph is an **orchestration framework** designed for building intelligent, stateful, and multi-step LLM workflows. Its core capability is to represent any LLM workflow as a **graph**.\n\n*   **Graph Representation**: When given an LLM workflow, LangGraph first attempts to represent it in the form of a graph.\n    *   **Nodes**: Each node in the graph represents a **single task** or sub-task within your workflow. These tasks can include calling an LLM, invoking a tool, or making a decision. Behind the scenes, each node is essentially a **Python function**.\n    *   **Edges**: Nodes are connected by edges, which indicate the **flow of execution** – specifically, which task should execute next after a particular node completes. Edges can represent sequential, parallel, conditional (branching), or looping flows.\n*   **Workflow Execution**: Once the graph is built, you provide input to the first node and trigger the workflow. LangGraph automatically executes all nodes in their correct order until the workflow is complete.\n*   **Key Features**: Beyond graph construction, LangGraph offers additional features for complex behaviors:\n    *   **Parallel Task Execution**: Allows multiple nodes to execute simultaneously.\n    *   **Loops (Cycles)**: Enables returning to a previous node for iterative processes.\n    *   **Branching**: Allows conditional execution paths based on certain conditions.\n    *   **Memory**: Supports recording conversation history and task execution details.\n    *   **Resumability**: Allows resuming a workflow from the point of breakdown if an issue occurs.\n*   **Suitability**: These features make LangGraph an ideal choice for building **agentic and production-grade AI applications**.\n\n### 2. Core Concept: LLM Workflows\nAn **LLM workflow** is a step-by-step process used to build complex LLM applications.\n\n*   **Workflow Definition**: A workflow is a series of tasks executed in a specific order to achieve a goal.\n*   **LLM Workflow Specifics**: An LLM workflow is characterized by the inclusion of Large Language Models (LLMs) in multiple tasks within the series of steps. For example, in an automated hiring process, tasks like drafting job descriptions, shortlisting candidates, or conducting interviews might all involve LLMs.\n*   **Task Types**: Each step in an LLM workflow performs a distinct task, such as:\n    *   Prompting\n    *   Reasoning\n    *   Tool calling\n    *   Memory access\n    *   Decision making\n*   **Workflow Structures**: Workflows can be:\n    *   **Linear**: Simple sequential execution.\n    *   **Parallel**: Multiple tasks executing simultaneously.\n    *   **Branch**: Conditional execution paths.\n    *   **Looped**: Repetitive execution of tasks.\n    These structures enable complex behaviors like retries, multi-agent communication, or tool-augmented reasoning.\n\n**Common LLM Workflow Patterns**:\n\n1.  **Prompt Chaining**:\n    *   **Concept**: Involves calling or interacting with LLMs multiple times in sequence.\n    *   **Use Case**: Used for complex tasks that can be broken down into sub-tasks, where the output of one LLM call serves as input for the next.\n    *   **Example**: Generating a detailed report from a topic. First LLM creates an outline, then a second LLM uses that outline to generate the full report. Checks can be integrated at intermediate steps (e.g., word count limits).\n\n2.  **Routing**:\n    *   **Concept**: An LLM acts as a decision-maker, understanding a task and deciding which specific LLM or path should execute it.\n    *   **Use Case**: Directing queries or tasks to the most capable agent or component.\n    *   **Example**: A customer support chatbot receiving a query (technical, refund, sales-related). A central LLM (router) analyzes the query and routes it to the appropriate specialized LLM for handling.\n\n3.  **Parallelization**:\n    *   **Concept**: A given task is broken down into multiple sub-tasks that are executed **simultaneously**. Their results are then merged to produce a final outcome.\n    *   **Use Case**: When sub-tasks are independent and can be processed concurrently to save time or enhance thoroughness.\n    *   **Example**: Content moderation for a platform like YouTube. A video is simultaneously checked by different LLMs for community guideline violations, misinformation, and sexual content. All results are aggregated to decide whether to publish the video.\n\n4.  **Orchestrator Worker Workflow**:\n    *   **Concept**: Similar to parallelization, but the **nature of the sub-tasks is not pre-defined** and is dynamically decided based on the input. An \"Orchestrator\" LLM analyzes the query and assigns specific, varied tasks to multiple \"Worker\" LLMs.\n    *   **Use Case**: Scenarios where the execution path and sub-tasks are highly variable and context-dependent.\n    *   **Example**: A research assistant creating a detailed research report. The Orchestrator LLM analyzes the query (e.g., scientific term vs. social phenomenon) and directs worker LLMs to search on specific platforms (e.g., Google Scholar vs. Google News) or perform different types of searches.\n\n5.  **Evaluator Optimizer Workflow**:\n    *   **Concept**: Designed for tasks that cannot be perfectly executed in a single go and require **iteration and refinement**. It involves a \"Generator\" LLM and an \"Evaluator\" LLM.\n    *   **Process**: The Generator produces a \"solution\" (e.g., an email draft, a blog post). The Evaluator then assesses this solution against concrete criteria. If rejected, the Evaluator provides feedback, which the Generator uses to create a new, improved solution. This process loops until the Evaluator accepts the solution.\n    *   **Use Case**: Creative tasks like drafting emails, writing blogs, poems, or stories, which naturally involve multiple drafts and revisions. This mimics how human writers work.\n\n### 3. Core Concepts: Graphs, Nodes, and Edges (Deep Dive)\n\n*   **Representing Workflows as Graphs**: LangGraph explicitly represents LLM workflows as graphs.\n*   **UPSC Essay Example**: An example is provided where a website helps UPSC aspirants practice essay writing.\n    *   **Workflow Steps**: Generate essay topic -> User writes and submits essay -> Evaluate essay from multiple perspectives (clarity, depth, language) -> Aggregate results -> Score essay -> If score > cutoff, congratulate; else, provide feedback and offer a chance to revise and resubmit. This entire process can involve iterations.\n    *   **Graph Visualization**: This complex, iterative workflow can be easily visualized as a graph, clearly showing nodes for each step (e.g., Topic Generation, Collect Essay, Evaluate Clarity, Evaluate Depth, Evaluate Language, Final Evaluation, Provide Feedback) and edges indicating the flow, including parallel execution for evaluation and a loop for revision.\n*   **Nodes as Python Functions**: Each node in a LangGraph graph is internally represented as a **Python function**. This means if you can write a Python function, you can create a node. The graph itself is a set of interconnected Python functions.\n*   **Edges Define Execution Flow**: Edges dictate *when* a node should execute. They specify the flow of execution between nodes.\n    *   **Types of Edges**:\n        *   **Sequential Edges**: One node executes after another.\n        *   **Parallel Edges**: Multiple nodes execute simultaneously.\n        *   **Conditional Edges (Branching)**: The flow diverges based on a condition, leading to one of several possible next nodes.\n        *   **Looping Edges**: The flow returns to a previous node, enabling iterative processes.\n    *   The graph structure, with its various edge types, provides the flexibility to express complex sequential, parallel, branching, and looping flows within an LLM workflow.\n\n### 4. Core Concept: State\n**State** is a critical component in LangGraph that acts as a **shared memory** flowing through the workflow.\n\n*   **Purpose**: It holds all the data passed between nodes as your graph runs. Any LLM workflow requires certain data points to guide its execution.\n*   **Characteristics**:\n    *   **Shared**: The entire state is accessible to **every node** at any moment during execution.\n    *   **Mutable**: Nodes can **modify or update** the state.\n    *   **Evolving**: The data in the state **evolves and changes over time** as the execution progresses.\n*   **Node Interaction with State**:\n    *   When a node executes, it receives the complete state as an **input**.\n    *   The node performs its task and makes **changes or partial updates** to this state.\n    *   The updated state is then passed on to the next node.\n*   **Implementation**: In code, the state is typically implemented as a **special dictionary** called a **Typed Dictionary** (a Python class), or sometimes a Pydantic object. You create an object of this class and add key-value pairs representing your data points (e.g., essay text, essay topic, individual scores, overall score in the UPSC example).\n*   **Importance**: State is a very important concept and heavily used when writing LangGraph code.\n\n### 5. Core Concept: Reducers\n**Reducers** are closely connected to the concept of State and define **how updates from nodes are applied to the shared state**.\n\n*   **Problem with Simple Replacement**: While nodes can update (replace) values in the state, this isn't always desirable. In a chatbot, for example, simply replacing the `message` in the state means the LLM loses context of previous messages, making continuous conversation impossible.\n*   **Reducer's Role**: Reducers address this by specifying the update policy:\n    *   **Replace**: The new data replaces the existing value (default behavior).\n    *   **Add**: New data is appended to the existing value (e.g., adding messages to a list for conversation history).\n    *   **Merge**: New data is merged with existing data (e.g., merging dictionaries).\n*   **Granularity**: Each key within the state can have its **own reducer**, meaning different data points in the state can have different update behaviors.\n*   **Use Cases**:\n    *   **Chatbots**: Essential for maintaining conversation history where new messages are \"added\" rather than replacing the previous one.\n    *   **Iterative Workflows**: In the UPSC essay example, if a student revises their essay multiple times, you might want to \"add\" each version to the state rather than replacing the previous one, allowing the student to see their evolution.\n    *   **Parallel Workflows**: Reducers are particularly useful when building parallel workflows, where multiple nodes might try to update the same state key, requiring a defined merging strategy.\n\n### 6. LangGraph's Execution Model\nLangGraph's execution model is inspired by **Google Pregel**, a system for large-scale graph processing. When you build and run a workflow in LangGraph, the following happens behind the scenes:\n\n1.  **Graph Definition**:\n    *   This is the initial phase where you define the **nodes**, **edges**, and the **state** (as a Typed Dictionary) of your workflow.\n\n2.  **Compilation**:\n    *   After defining the graph, you **compile** it.\n    *   **Purpose**: This step checks for the **logical correctness** of the graph's structure, ensuring there are no inconsistencies, such as \"orphaned nodes\" (nodes not connected to others).\n\n3.  **Execution Phase**:\n    *   **Invocation**: Execution begins with an \"invocation,\" where you pass the **initial state** to the **first node** of your graph. This activates the first node, and its associated Python function is called.\n    *   **Partial State Update**: The active node performs its task and makes a **partial update** to the state.\n    *   **Message Passing**: Once the state is updated, it is **automatically passed** through the edges to the next connected node(s). This process of continuously using edges to send the state to subsequent nodes is called **message passing**.\n    *   **Supersteps**: The execution proceeds in rounds. Each round of activity, where nodes are activated, update the state, and pass messages, is called a **superstep**.\n        *   **Why \"Superstep\"?**: A superstep might involve **more than one step** executing in parallel. For example, if a node's output leads to three parallel nodes, all three will activate and perform updates simultaneously within a single superstep. LangGraph uses \"superstep\" to account for this potential for parallel invocations, rather than just \"step\".\n    *   **State Aggregation (with Reducers)**: If multiple parallel nodes update the state, their changes are merged using **reducers** before being passed to the next aggregate node.\n    *   **Workflow Termination**: The entire execution stops when there are **no active nodes** and **no messages are passing** through the edges. LangGraph automates the node calling and state passing; you don't manually call each node sequentially.\n\n### Conclusion\nUnderstanding these core concepts—LLM Workflows, Graphs (Nodes and Edges), State, Reducers, and the Execution Model—is fundamental for effectively working with LangGraph. This conceptual overview prepares you for practical coding, making future hands-on experience feel more familiar and intuitive.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}